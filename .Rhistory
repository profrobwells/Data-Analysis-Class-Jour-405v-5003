'150k_to_199_999','200k_plus','median_income','mean_income',
'pct_allocated_household_income','pct_allocated_family_income','pct_allocated_nonfamily_income'))
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(Low_Wage_Households = rowSums(.[5:7]))
# Learn about packages and commands
browseVignettes("rio")
??rio
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(Low_Wage_Households = rowSums(.[5:14]))
#The Urls function deals cleans links and symbols, and can be applied on any object.
library(tidytext)
library(tm)
??tm
install.packages("tm")
library(tm)
Urls <- function(x) {
removeATUser <- function(x) gsub("@[a-z,A-Z]*","",x)
removeEmoji <- function(x) gsub("\\p{So}|\\p{Cn}", "", x, perl = TRUE)
removeSpecialChar <- function(x) gsub("[^[:alnum:]///' ]", "", x)
removeURL <- function(x) gsub('http[[:alnum:]]*', '', x)
return(x)
}
getwd()
AOC <- rio::import('/Data/AOC.csv)
AOC <- rio::import('/Data/AOC.csv')
)
()
''
AOC <- rio::import('/Data/AOC.csv')
AOC <- rio::import('Data/AOC.csv')
tm_clean <- function(x) {
x <- tm_map(x, content_transformer(Urls))   ### NOTE  that Urls function embedded within the tm_clean function, which means Urls function should run in the memory prior to the tm function to work.
x <- tm_map(x, content_transformer(tolower))
x <- tm_map(x, removePunctuation)
x <- tm_map(x, removeNumbers)
x <- tm_map(x, removeWords, c(stopwords("en"), "âin", "httpstcobvcdfknxc", "â€œ", 'arpx', 'djt',  'aafs',  'rt', 'text', 'will', 'go', 'day', 'year', 'today', 'etc', 'lizannsond', 'arkansa', 'amp', 'arleg', 'also', 'now',  'arleg', 'collinsark', 'fayetteville', 'arkansas'))
x <- tm_map(x, stripWhitespace)
return(x)
}
colnames(AOC)
AOC_tidy <- AOC$text %>%
VectorSource() %>%
VCorpus() %>%
tm_clean() %>%
DocumentTermMatrix() %>%
tidy()
library(dplyr)
AOC_tidy <- AOC$text %>%
VectorSource() %>%
VCorpus() %>%
tm_clean() %>%
DocumentTermMatrix() %>%
tidy()
View(AOC_tidy)
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
library(dplyr)
library(stringr)
library(readr)
library(devtools)
install.packages("devtools")
library(devtools)
NYT <- read_lines("NYT1_26.txt")
NYT <-as.data.frame(NYT)
colnames(NYT)[1] <- "Text"
View(NYT)
NYT$Start <-
gsub("____________________________________________________________",
"STARTOFARTICLE", NYT$Text)
View(NYT)
NYT2 <- NYT %>%
mutate(linenumber = row_number(),
newarticle = cumsum(str_detect(Start, regex("STARTOFARTICLE",
ignore_case = TRUE, na.rm=TRUE)))) %>%
ungroup()
View(NYT2)
NYT2 <- NYT2[!(is.na(NYT2$Start) | NYT2$Start==""), ]
NYT3 <- NYT2
cutmeta <- c('Author:', 'Publication Info', 'http://',
'Company:', 'Country of publication:', 'Dateline:', 'Document feature:',
'Document type:', 'Location:', 'Number of pages:', 'Place of publication:',
'Publication title:', 'Publication year:', 'Publisher:', 'Section:',
'Source type:', 'Subject:', 'Company / organization: ', 'Credit:')
NYT4 <- NYT3[ !grepl(paste(cutmeta, collapse="|"), NYT3$Start),]
View(NYT4)
NYT_Tidy_Headlines <- NYT4 %>%
select(Start, newarticle) %>%
filter(str_detect(Start, "Title: "))
View(NYT_Tidy_Headlines)
library(data.table)
setnames(NYT4, old = c('Text', 'Start', 'linenumber', 'newarticle'), new = c('x', 'text', 'line', 'article_nmbr'))
NYT4 <- select(NYT4, c(text, line, article_nmbr))
View(NYT4)
NYT4 <- NYT4 %>%
mutate(linenumber = row_number())
library(data.table)
setnames(NYT_Tidy_Headlines, old = c('Start','newarticle'), new = c('headline','article_nmbr'))
NYT_tidy <- inner_join(NYT_Tidy_Headlines, NYT4, by =c("article_nmbr" = "article_nmbr"))
NYT_tidy <- select(NYT_tidy, c(headline, article_nmbr, text, linenumber))
View(NYT_tidy)
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
NYT_token <- NYT_tidy %>%
filter(!str_detect(text, '^"')) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|&amp;", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
View(NYT_token)
NYT_token$word2 <-
gsub("'","", NYT_token$word)
colnames(NYT_token)[4] <- "word"
CommonNYTWords <- NYT_token %>%
count(word) %>%
filter(sum(n) >= 5) %>%
ungroup()
View(CommonNYTWords)
NYT_token$word2 <-
gsub("'","", NYT_token$word)
NYT_token <- select (NYT_token, c(headline, article_nmbr, linenumber, word2))
colnames(NYT_token)[4] <- "word"
CommonNYTWords <- NYT_token %>%
count(word) %>%
filter(sum(n) >= 5) %>%
ungroup()
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
totalwords <- NYT_token %>%
group_by(article_nmbr) %>%
mutate(total_words = n()) %>%
ungroup() %>%
distinct(article_nmbr, total_words)
library(tidyselect)
NYT_sentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
select(word, sentiment, n) %>%
arrange(desc(n))
View(NYT_sentiment)
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
complete(sentiment, fill = list(n = 0)) %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
total_NYTsentiment <- select (total_NYTsentiment, c(-nn))
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
complete(sentiment, fill = list(n = 0)) %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
library(tidyselect)
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
complete(sentiment, fill = list(n = 0)) %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
View(nrc)
View(CommonNYTWords)
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
complete(sentiment, fill = 0) %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
??complete
library(devtools)
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
complete(sentiment, fill = list(n = 0)) %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
complete(sentiment, fill = list(n = 0)) %>%
group_by(sentiment, n) %>%
summarize(words = sum(n)) %>%
arrange(desc(words)) %>%
ungroup()
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
group_by(sentiment, n) %>%
summarize(words = sum(n)) %>%
arrange(desc(words)) %>%
ungroup()
total_NYTsentiment <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
View(total_NYTsentiment)
total_NYTsentiment2 <- CommonNYTWords %>%
inner_join(nrc, by = "word") %>%
count(sentiment) %>%
ungroup() %>%
spread(sentiment) %>%
group_by(sentiment, nn) %>%
summarize(words = sum(nn)) %>%
arrange(desc(words)) %>%
ungroup()
stop_words
stop <- stop_words
View(stop)
StudentLoans <- rio::import('./Data/AR2016_SMALL.csv')
#What is the character type?
library(dplyr)
StudentLoans[10:102] <- lapply(StudentLoans[10:102], as.numeric)
glimpse(StudentLoans)
#Load Data
ArkCo_Income_2017 <- rio::import("Data/ArkCo_Income_2017.csv")
ArkCo_Income_2017 <- rio::import("Data/ArkCo_Income_2017.csv", skip=1)
View(ArkCo_Income_2017)
# Clean up column names to they are R friendly
ArkCo_Income_2017 <- janitor::clean_names(ArkCo_Income_2017)
# Still need to fix column names
colnames(ArkCo_Income_2017)
data.table::setnames(ArkCo_Income_2017, old = c('id', 'id2', 'geography', 'households_estimate_total',
'households_estimate_less_than_10_000', 'households_estimate_10_000_to_14_999',
'households_estimate_15_000_to_24_999', 'households_estimate_25_000_to_34_999',
'households_estimate_35_000_to_49_999', 'households_estimate_50_000_to_74_999',
'households_estimate_75_000_to_99_999', 'households_estimate_100_000_to_149_999',
'households_estimate_150_000_to_199_999', 'households_estimate_200_000_or_more',
'households_estimate_median_income_dollars', 'households_estimate_mean_income_dollars',
'households_estimate_percent_allocated_household_income_in_the_past_12_months',
'households_estimate_percent_allocated_family_income_in_the_past_12_months',
'households_estimate_percent_allocated_nonfamily_income_in_the_past_12_months'),
new = c('id','id2','geography','households_estimate_total','less10_000','10k_to_14_999','15k_to_24_999',
'25k_to_34_999', '35k_to_49_999','50k_to_74_999','75k_to_99_999','100k_to_149_999',
'150k_to_199_999','200k_plus','median_income','mean_income',
'pct_allocated_household_income','pct_allocated_family_income','pct_allocated_nonfamily_income'))
View(ArkCo_Income_2017)
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(Low_Wage_Households = rowSums(.[5:7]))
colnames(ArkCo_Income_2017)
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(WorkingClass = rowSums(.[8:9]))
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(MiddleClass = rowSums(.[10:12]))
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(UpperIncome = rowSums(.[13:14]))
ArkCo_Income_2017$LowWagePop <- ((ArkCo_Income_2017$Low_Wage_Households/ArkCo_Income_2017$households_estimate_total)/100)
ArkCo_Income_2017$LowWagePop <- ((ArkCo_Income_2017$households_estimate_total*ArkCo_Income_2017$Low_Wage_Households)/100)
ArkCo_Income_2017$WorkingClassPop <- ((ArkCo_Income_2017$households_estimate_total*ArkCo_Income_2017$WorkingClass)/100)
ArkCo_Income_2017$MiddleClassPop <- ((ArkCo_Income_2017$households_estimate_total*ArkCo_Income_2017$MiddleClass)/100)
ArkCo_Income_2017$UpperIncomePop <- ((ArkCo_Income_2017$households_estimate_total*ArkCo_Income_2017$UpperIncome)/100)
colnames(ArkCo_Income_2017)
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(SumPop = rowSums(.[24:27]))
#Eyeball the two columns, household_estimate_total and our SumPop
#df1 <- select(AR2016ALL, V4:V8, V10:20)
PopCheck <- select(ArkCo_Income_2017, household_estimate_total, SumPop)
#Eyeball the two columns, household_estimate_total and our SumPop
#df1 <- select(AR2016ALL, V4:V8, V10:20)
PopCheck <- select(ArkCo_Income_2017, households_estimate_total, SumPop)
View(PopCheck)
PopCheck$variance <- (ArkCo_Income_2017$households_estimate_total- ArkCo_Income_2017$SumPop)
colnames(ArkCo_Income_2017)
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(SumIndivdPct = rowSums(.[5:14]))
ArkCo_Income_2017 <- ArkCo_Income_2017 %>%
replace(is.na(.), 0) %>%
mutate(SumGroupPct = rowSums(.[20:23]))
PopCheck <- select(ArkCo_Income_2017, households_estimate_total, SumPop, variance, SumIndivdPct, SumGroupPct)
PopCheck <- select(ArkCo_Income_2017, households_estimate_total, SumPop, SumIndivdPct, SumGroupPct)
View(PopCheck)
#Quick Data Viz
#Basic graphs
plot(ArkCo_Income_2017$median_income)
hist(ArkCo_Income_2017$median_income)
barplot(ArkCo_Income_2017$median_income)
barplot(sort(ArkCo_Income_2017$median_income, decreasing = TRUE))
#load software
pacman::p_load(ggplot2, dplyr, usethis, forcats)
library(devtools)
install_github("trinker/pacman")
library(pacman)
install.packages(pacman)
??version
??update r
??updateR
devtools::install_github("AndreaCirilloAC/updateR")
## Make sure your current packages are up to date
update.packages()
#load software
pacman::p_load(ggplot2, dplyr, usethis, forcats)
libary(ggplot)
library(ggplot)
library("ggplot)
library("ggplot")
install.packages("ggplot")
library("ggplot")
library(ggplot)
library(ggplot2)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
install.packages("usethis")
install.packages("usethis")
library(usethis)
install.packages("forcats")
install.packages("forcats")
library(forcats)
#Basic demo
demo(topic="graphics")
#Tutorial
snowdata <- rio::import("data/BostonChicagoNYCSnowfalls.csv")
bostonsnow <- select(snowdata, Winter, Boston)
names(bostonsnow)[2] <- "TotalSnow"
bostonsnow <- select(snowdata, Winter, Boston) %>%
rename(TotalSnow = Boston)
bostonsnow <- select(snowdata, Winter, TotalSnow = Boston)
#Basic graphs
plot(bostonsnow$TotalSnow)
hist(bostonsnow$TotalSnow)
boxplot(bostonsnow$TotalSnow)
barplot(bostonsnow$TotalSnow)
barplot(sort(bostonsnow$TotalSnow, decreasing = TRUE))
#qplot
qplot(data=bostonsnow, y = TotalSnow)
qplot(y = bostonsnow$TotalSnow)
#bring in snowdata tidy
snowdata_tidy <- rio::import("data/snowdata_tidy.csv")
#view a tidy table
view(snowdata_tidy)
#view a tidy table
View(snowdata_tidy)
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line() +
geom_point()
ggplot(data = snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_col()
ggplot(data = snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, fill = City)) +
geom_col(position = "dodge")
ggplot(data=snowdata) +
geom_boxplot(aes(x = "Boston", y = Boston))
ggplot(data=snowdata) +
geom_boxplot(aes(x = "Boston", y = Boston)) +
geom_boxplot(aes(x = "Chicago", y = Chicago))
ggplot(snowdata_tidy, aes(x = City, y = TotalSnow)) +
geom_boxplot()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City)) +
geom_line()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line() +
geom_point()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line()
snowdata_tidy21 <- filter(snowdata_tidy, Winter >= "1999-2000")
ggplot(snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line() +
geom_point()
ggplot(data = snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_col()
ggplot(data = snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, fill = City)) +
geom_col(position = "dodge")
ggplot(snowdata_tidy21, aes(Winter, TotalSnow, group = City, fill = City)) +
geom_col(position = "dodge")
boston10 <- bostonsnow %>%
top_n(10, TotalSnow) %>%
arrange(desc(TotalSnow))
ggplot(data = boston10, aes(x = Winter, y = TotalSnow)) +
geom_col(fill = "rainbow") +
theme_minimal()
install.packages(dplyr)
install.packages("dplyr")
?library
wtf()
??wtf
??TIDYVERSE
browseVignettes(Tidyverse)
browseVignettes(TidyVerse)
browseVignettes('tidyverse')
browseVignettes(tidyverse)
browseVignettes(readxl)
browseVignettes("readxl")
browseVignettes("dplyr")
help(dplyr)
?dplyr
library(readr)
Arakansas_crime <- read_csv("~/Dropbox/Classes/Materials for Data Analysis Spring 2019 Jour 405v Jour 5003/Arkansas Crime R Lesson/Arakansas_crime.csv")
View(Arakansas_crime)
Arakansas_crime <- rio::("~/Data/arkansas_crime.xls")
Arakansas_crime <- rio::"~/Data/arkansas_crime.xls"
Arakansas_crime <- rio::import("~/Data/arkansas_crime.xls")
Arakansas_crime <- rio::import("./Data/arkansas_crime.xls")
View(Arakansas_crime)
??hist
#Tutorial
#Import Data, Create Dataframe, Rename Columns
snowdata <- rio::import("data/BostonChicagoNYCSnowfalls.csv")
bostonsnow <- select(snowdata, Winter, Boston)
library(dplyr)
bostonsnow <- select(snowdata, Winter, Boston)
View(bostonsnow)
names(bostonsnow)[2] <- "TotalSnow"
bostonsnow <- select(snowdata, Winter, Boston) %>%
rename(TotalSnow = Boston)
bostonsnow <- select(snowdata, Winter, TotalSnow = Boston)
#Basic graphs
plot(bostonsnow$TotalSnow)
hist(bostonsnow$TotalSnow)
boxplot(bostonsnow$TotalSnow)
barplot(bostonsnow$TotalSnow)
barplot(sort(bostonsnow$TotalSnow, decreasing = TRUE))
#qplot
qplot(data=bostonsnow, y = TotalSnow)
bostonsnow <- select(snowdata, Winter, Boston)
names(bostonsnow)[2] <- "TotalSnow"
bostonsnow2 <- select(snowdata, Winter, Boston) %>%
rename(TotalSnow = Boston)
View(bostonsnow2)
bostonsnow3 <- select(snowdata, Winter, TotalSnow = Boston)
View(bostonsnow3)
#bring in snowdata tidy
snowdata_tidy <- rio::import("data/snowdata_tidy.csv")
#view a tidy table
View(snowdata_tidy)
ggplot(snowdata_tidy, aes(x = City, y = TotalSnow)) +
geom_boxplot()
#call software into memory
library(ggplot2)
ggplot(data=snowdata) +
geom_boxplot(aes(x = "Boston", y = Boston))
ggplot(data=snowdata) +
geom_boxplot(aes(x = "Boston", y = Boston)) +
geom_boxplot(aes(x = "Chicago", y = Chicago))
snowdata_tidy <- rio::import("data/snowdata_tidy.csv")
ggplot(snowdata_tidy, aes(x = City, y = TotalSnow)) +
geom_boxplot()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City)) +
geom_line()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line() +
geom_point()
ggplot(snowdata_tidy, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line()
snowdata_tidy21 <- filter(snowdata_tidy, Winter >= "1999-2000")
ggplot(snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_line() +
geom_point()
ggplot(data = snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, color = City)) +
geom_col()
ggplot(data = snowdata_tidy21, aes(x = Winter, y = TotalSnow, group = City, fill = City)) +
geom_col(position = "dodge")
colnames(bostonsnow)
TopGrowthChart <- ggplot(bostonsnow, aes(x = reorder(winter, -TotalSnow), y = TotalSnow))  +
geom_bar(stat = "identity") +
coord_flip() +
labs(title = "Snow",
subtitle = "lots of it",
caption = "Graphic by Rob Wells",
x="Years",
y="snow in inches")
plot(TopGrowthChart)
TopGrowthChart <- ggplot(bostonsnow, aes(x = reorder(Winter, -TotalSnow), y = TotalSnow))  +
geom_bar(stat = "identity") +
coord_flip() +
labs(title = "Snow",
subtitle = "lots of it",
caption = "Graphic by Rob Wells",
x="Years",
y="snow in inches")
plot(TopGrowthChart)
TopGrowthChart <- ggplot(bostonsnow, aes(x = reorder(Winter, TotalSnow), y = TotalSnow))  +
geom_bar(stat = "identity") +
coord_flip() +
labs(title = "Snow",
subtitle = "lots of it",
caption = "Graphic by Rob Wells",
x="Years",
y="snow in inches")
plot(TopGrowthChart)
boston10 <- bostonsnow %>%
top_n(10, TotalSnow) %>%
arrange(desc(TotalSnow))
ggplot(boston10, aes(x=fct_reorder(Winter, TotalSnow), y=TotalSnow)) +
geom_col()
